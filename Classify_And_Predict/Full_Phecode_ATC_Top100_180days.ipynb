{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8da002af-df1a-48a0-bb90-f4595b5a2fe8",
   "metadata": {},
   "source": [
    "### Classification and Predicition - Full_Phecode_ATC_Top100_180days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6dd72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Evaluation result TNE_BO_180 as dependent variable ******\n",
      "Accuracy: 0.6493258426966292\n",
      "Precision: 0.052129688493324854\n",
      "Recall: 0.5412541254125413\n",
      "F1score: 0.09510002899391126\n",
      "Confused matrix:\n",
      "[[5615 2982]\n",
      " [ 139  164]]\n",
      "True Negative (TN): 5615\n",
      "False Positive (FP): 2982\n",
      "False Negative (FN): 139\n",
      "True Positive (TP): 164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.65      0.78      8597\n",
      "         1.0       0.05      0.54      0.10       303\n",
      "\n",
      "    accuracy                           0.65      8900\n",
      "   macro avg       0.51      0.60      0.44      8900\n",
      "weighted avg       0.94      0.65      0.76      8900\n",
      "\n",
      "\n",
      "****** Prediction Model Evaluation result  TNE_NO_180 as dependent variable ******\n",
      "R-squared: -0.09434335855694775\n",
      "Mean squared error: 2688.2374327099797\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score,confusion_matrix,precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import os\n",
    "#from dotenv import load_dotenv\n",
    "#load_dotenv()\n",
    "\n",
    "\n",
    "######### Split Medication and Diagnosis In Unique Pieces ############\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "#                                                                    #\n",
    "######################################################################\n",
    "\n",
    "class Full_Phecode_ATC_ClassifyReadmissionWithMedicationDiagnosis:\n",
    "    def __init__(self, file1):\n",
    "        self.file1 = file1\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "        self.without_diag_medic_selected_column_merged_df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        Full_Phecode_ATC = pd.read_csv(self.file1)       \n",
    "        self.merged_df = Full_Phecode_ATC[['episode_id', 'num_diagnoses', 'num_medications', 'pasient', 'age',\n",
    "       'remaining_time_countdown', 'var_no_dates_permonth', 'gender',\n",
    "       'episode_order', 'islast', 'closingcode', 'aftercode',\n",
    "       'episode_start_date', 'episode_end_date', 'tillnextepisode',\n",
    "       'Length_of_Episode', 'Cat_LOE', 'TNE_BO_180', 'TNE_NO_180',\n",
    "       'TNE_BO_365', 'TNE_NO_365', 'TNE_BO_730', 'TNE_NO_730', 'TNE_BO_1095',\n",
    "       'TNE_NO_1095', 'Cat_LOE_desc', 'Count_visit', 'Cat_CV', 'Therapy_ratio',\n",
    "       'Examination_ratio', 'Advisory_ratio', 'TreatmentPlanning_ratio',\n",
    "       'Outpatient_ratio', 'Inpatient_ratio', 'Inpatient_day_ratio',\n",
    "       'Inpatient_daynight_ratio', 'Care_intensity', 'age_group',\n",
    "       'closingcode_0', 'closingcode_1', 'closingcode_2', 'closingcode_3',\n",
    "       'closingcode_4', 'closingcode_5', 'closingcode_6', 'closingcode_9',\n",
    "       'aftercode_1', 'aftercode_2', 'aftercode_3', 'aftercode_4',\n",
    "       'aftercode_5', 'gender_0', 'F', 'M', 'MiddleChildhood', 'Preschooler',\n",
    "       'Teenager', 'actual_diag_Phe', 'actual_med_Full_ATC']]\n",
    "        self.merged_df = self.merged_df.copy(deep=True)\n",
    "        return self.merged_df\n",
    "\n",
    "\n",
    "     ##### Split Diagnose and Medication, and save new dataframe  \n",
    "    def split_diagnosis_medication(self):\n",
    "        newmerged_df = Full_Phecode_ATC_ClassifyReadmissionWithMedicationDiagnosis_Obj.load_data()\n",
    "        columns = ['actual_diag_Phe', 'actual_med_Full_ATC']\n",
    "        lists_dict = {}\n",
    "        diagnoses_list = []\n",
    "        actual_med_list = [] \n",
    "        for col in columns:\n",
    "            newmerged_df[col] = newmerged_df[col].apply(lambda d:[] if pd.isnull(d) else d)\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"[\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"]\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\"'\", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.replace(\" \", \"\")\n",
    "            newmerged_df[col] = newmerged_df[col].str.split(',')\n",
    "            newmerged_df = newmerged_df.explode(col)\n",
    "            \n",
    "            # Show only top 100 columns names\n",
    "            temp_store_100 = newmerged_df[col].value_counts().head(100)\n",
    "            names_only = temp_store_100.index.tolist()\n",
    "            lists_dict[col] = names_only\n",
    "            #print(names_only)\n",
    "\n",
    "            if col =='actual_diag_Phe':\n",
    "                diagnoses_list = lists_dict[col]\n",
    "            else:\n",
    "                actual_med_list = lists_dict['actual_med_Full_ATC']\n",
    "\n",
    "            original_columns = newmerged_df.columns.tolist()\n",
    "            dummies = newmerged_df[col].str.get_dummies(sep=',')\n",
    "            newmerged_df = pd.concat([newmerged_df, dummies], axis=1)\n",
    "            newmerged_df = newmerged_df.drop(col, axis=1)\n",
    "\n",
    "        newmerged_df.to_csv('/mnt/work/workbench/dipendrp/new-data/Unique_Full_Phecode_ATC.csv',index=False)\n",
    "        concatenated_df = pd.concat([newmerged_df.iloc[:, :57], newmerged_df[diagnoses_list], newmerged_df[actual_med_list]], axis=1)\n",
    "        concatenated_df.to_csv('/mnt/work/workbench/dipendrp/new-data/Top100_Full_Phecode_ATC.csv',index=False)  \n",
    "       \n",
    "    \n",
    "class ClassifyReadmissionWithMedicationDiagnosis:\n",
    "    def __init__(self, file2):\n",
    "        self.file2 = file2\n",
    "        self.merged_df = None\n",
    "        self.selected_column_merged_df = None\n",
    "    \n",
    "    def load_data(self):\n",
    "        self.merged_df = pd.read_csv(self.file2)\n",
    "        columns_to_remove = ['pasient', 'age','episode_id','episode_order', 'gender', 'age_group', 'islast', 'closingcode', 'aftercode', 'Inpatient_ratio', 'Inpatient_day_ratio','episode_start_date', 'episode_end_date', 'tillnextepisode', 'Cat_LOE','Cat_LOE_desc', 'Cat_CV','TNE_BO_365', 'TNE_NO_365', 'TNE_BO_730', 'TNE_NO_730', 'TNE_BO_1095','TNE_NO_1095', 'nan']\n",
    "        self.merged_df = self.merged_df.drop(columns=columns_to_remove)\n",
    "\n",
    "        # fill nan values in independent column\n",
    "        self.merged_df['num_diagnoses'].fillna(0, inplace=True)\n",
    "        self.merged_df['num_medications'].fillna(0, inplace=True)\n",
    "        self.merged_df['Outpatient_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Inpatient_daynight_ratio'].fillna(0, inplace=True)  \n",
    "        self.merged_df['Therapy_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Examination_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['Advisory_ratio'].fillna(0, inplace=True)\n",
    "        self.merged_df['TreatmentPlanning_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_BO_180 = self.merged_df[['TNE_BO_180']]\n",
    "        self.independent_variable = self.merged_df.drop(columns=['TNE_BO_180', 'TNE_NO_180'])\n",
    "\n",
    "        columns_with_nan = self.independent_variable.columns[self.independent_variable.isnull().any()].tolist()\n",
    "\n",
    "        return self.merged_df, self.dependent_variable_TNE_BO_180, self.independent_variable \n",
    "    \n",
    "    # To train and view the reasult of binary and multiclass classifier        \n",
    "    def train_classifier_with_medication_diagnosis(self):\n",
    "        dependent_variables = [self.dependent_variable_TNE_BO_180]\n",
    "        \n",
    "        # to define the weight of output class, to resolve imbalanced output/dataset\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_BO_180': 'TNE_BO_180'}\n",
    "        class_weights = {'TNE_BO_180': {0:10, 1:270}}\n",
    "              \n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            logistic_prediction_model = LogisticRegression(class_weight=class_weights[variable_name])\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            logistic_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = logistic_prediction_model.predict(X_test)\n",
    "            \n",
    "            # Checks if the output category for classification is binary or multiclass\n",
    "            category_count = int(y_train.nunique())\n",
    "            print(f'\\n****** Evaluation result {variable_name} as dependent variable ******')\n",
    "            # For binary class classification \n",
    "            if category_count == 2:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='binary')\n",
    "                recall = recall_score(y_test, y_pred, average='binary')\n",
    "                f1 = f1_score(y_test, y_pred, average='binary')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                print(\"Confused matrix:\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                tn, fp, fn, tp = conf_matrix.ravel()\n",
    "                print(conf_matrix)\n",
    "                print(f\"True Negative (TN): {tn}\")\n",
    "                print(f\"False Positive (FP): {fp}\")\n",
    "                print(f\"False Negative (FN): {fn}\")\n",
    "                print(f\"True Positive (TP): {tp}\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # For binary class classification \n",
    "            else:\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='weighted')\n",
    "                recall = recall_score(y_test, y_pred, average='weighted')\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "                \n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print(f\"F1score: {f1}\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                print(\"Confused matrix:\")\n",
    "                print(conf_matrix)\n",
    "                print(classification_report(y_test, y_pred))\n",
    "                \n",
    "    def prediction_with_medication_diagnosis(self):\n",
    "        # Select all corresponding columns with values in TNE_NO_180\n",
    "        self.merged_df = self.merged_df.dropna(subset=['TNE_NO_180'])\n",
    "        \n",
    "        # define dependent variables\n",
    "        self.dependent_variable_TNE_NO_180 = self.merged_df[['TNE_NO_180']]\n",
    "        # define independent variables\n",
    "        self.independent_variable = self.merged_df.drop(columns=['TNE_BO_180', 'TNE_NO_180'])\n",
    "\n",
    "        dependent_variables = [self.dependent_variable_TNE_NO_180]\n",
    "        dependent_variable_names = {'self.dependent_variable_TNE_NO_180':'TNE_NO_180'}\n",
    "        #for dependent_variable in dependent_variables:\n",
    "        for variable_name, dependent_variable in zip(dependent_variable_names.values(), dependent_variables):\n",
    "            linear_prediction_model = LinearRegression()\n",
    "            X_train, X_temp, y_train, y_temp = train_test_split(self.independent_variable, dependent_variable, train_size=0.7)\n",
    "            X_test,X_eval,y_test,y_eval = train_test_split(X_temp,y_temp,test_size=0.33)\n",
    "            linear_prediction_model.fit(X_train,y_train)\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            print(f'\\n****** Prediction Model Evaluation result  {variable_name} as dependent variable ******')\n",
    "            y_pred = linear_prediction_model.predict(X_test)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print('R-squared:', r2)\n",
    "            print('Mean squared error:', mse)\n",
    "                \n",
    "\n",
    "Full_Phecode_ATC_ClassifyReadmissionWithMedicationDiagnosis_Obj = Full_Phecode_ATC_ClassifyReadmissionWithMedicationDiagnosis('/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC.csv')\n",
    "Full_Phecode_ATC_ClassifyReadmissionWithMedicationDiagnosis_Obj.split_diagnosis_medication()\n",
    "\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj = ClassifyReadmissionWithMedicationDiagnosis('/mnt/work/workbench/dipendrp/new-data/Top100_Full_Phecode_ATC.csv')\n",
    "merged_df, dependent_variable_TNE_BO_180, independent_variable  = ClassifyReadmissionWithMedicationDiagnosis_Obj.load_data()\n",
    "\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.train_classifier_with_medication_diagnosis()\n",
    "ClassifyReadmissionWithMedicationDiagnosis_Obj.prediction_with_medication_diagnosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f863f24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_diag_Phe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['3001', '3009']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['3895']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['29622']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17120</th>\n",
       "      <td>['3131', '3132']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17121</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17122</th>\n",
       "      <td>['3131', '3695', '312']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17123</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17124</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17125 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               actual_diag_Phe\n",
       "0             ['3001', '3009']\n",
       "1                          NaN\n",
       "2                     ['3895']\n",
       "3                    ['29622']\n",
       "4                          NaN\n",
       "...                        ...\n",
       "17120         ['3131', '3132']\n",
       "17121                      NaN\n",
       "17122  ['3131', '3695', '312']\n",
       "17123                      NaN\n",
       "17124                      NaN\n",
       "\n",
       "[17125 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Full_Phecode_ATC = pd.read_csv('/mnt/work/workbench/dipendrp/new-data/Full_Phecode_ATC.csv') \n",
    "Full_Phecode_ATC[['actual_diag_Phe']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Kernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
